{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd60e77b",
   "metadata": {},
   "source": [
    "**Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5232f412",
   "metadata": {},
   "source": [
    "This notebook serves as gateway to the projects located in this repository. Each of these projects were for a competitions on [modelshare.org](https://www.modelshare.ai/). I will go through each project, briefly listing what the analysis is about, the data that was used in the project, and the different architectures of my most successful models. At the end of each project section there will be a link to the repository which houses all the code I wrote.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62639279",
   "metadata": {},
   "source": [
    "*1. World Happiness Report*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b03d9eb",
   "metadata": {},
   "source": [
    "This project focuses on the [World Happiness Report dataset](https://worldhappiness.report/ed/2022/happiness-benevolence-and-trust-during-covid-19-and-beyond/#ranking-of-happiness-2019-2021), which provides information on the factors that contribute to a country's happiness, such as GDP per capita, corruption perception, and life expectancy. The dataset has been modified for a competition, with the target variable categorized into very low, low, average, high, and very high happiness levels.\n",
    "\n",
    "To build a machine learning model that predicts happiness levels, I experimented with different algorithms, including Neural Nets, Gradient Boosting, Logistic Regression, and Support Vector Machines. After testing, I found that Random Forest and Gradient Boosting had the best performance, while Logistic Regression had the worst accuracy. Interestingly, the automatic feature selection using SelectFromModel did not improve the model's performance, perhaps due to the limited data and features available. To optimize the model, I used GridSearchCV for hyper-parameter tuning.\n",
    "\n",
    "My best model (Random Forest) placed 104th out of 951 models on the public leaderboard.\n",
    "\n",
    "Link to main repository: [World Happiness Analysis](https://github.com/timnyt/ML-Projects/tree/main/World%20Happiness%20Report%20-%20Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc63a2f2",
   "metadata": {},
   "source": [
    "*2. COVID-19 Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8406b",
   "metadata": {},
   "source": [
    "The dataset used in this project is from M.E.H. Chowdhury et al.'s study, [\"Can AI help in screening Viral and COVID-19 pneumonia?\" (2020)](https://arxiv.org/abs/2003.13145), which contains digital chest X-ray images of individuals diagnosed with COVID-19, viral pneumonia, and those who are not sick. The aim of their study was to classify chest X-ray images accurately using pre-trained machine learning algorithms. In this project I tried to build on what had been done and attempt to transform the data and implement various machine learning approaches to improve upon the original methodology.\n",
    "\n",
    "After testing various architectures, I identified my three best models as a CNN, an MLP, and a transfer learning model. The transfer learning model achieved the highest accuracy (90.6%), followed by the CNN model (89.7%) and the MLP (85.4%). During the tuning process, I discovered that removing the dropout layer, reducing the number of convolutional layers before each max pooling layer, removing the last pooling layer, and increasing the epochs improved the performance of all models. However, changing to average pooling instead of max, adding strides, and adding a batch normalization layer decreased the scores of all models.\n",
    "\n",
    "My best model (Transfer Learning) placed 51st out of 827 models on the private leaderboard.\n",
    "\n",
    "Link to main repository: [COVID-19 Classification Analysis](https://github.com/timnyt/ML-Projects/tree/main/COVID%20-%2019%20Classification%20Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cd6187",
   "metadata": {},
   "source": [
    "*3. SST - Sentiment Analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541126a",
   "metadata": {},
   "source": [
    "This project analyzes a modified version of the Stanford SST Sentiment Dataset consisting of 8741 movie review sentences classified as either positive or negative. The goal is to understand how language composition affects sentiment, which has practical applications such as automating sentiment analysis of large text data like product reviews or social media posts. This analysis can aid businesses in improving their products, services, and marketing strategies. Additionally, the model can be used in chatbots or virtual assistants to better understand and respond to users' needs and emotions.\n",
    "\n",
    "After experimenting with different model architectures, a tuned sequential model with an LSTM layer and an embedding layer achieved the best performance with a cross-validation accuracy of 0.79. The Conv1D layer and embedding layer model performed slightly worse with an accuracy of 0.78, while the transfer learning model had the worst performance with an accuracy of only 0.65. The LSTM layer was found to be more effective in improving performance. Surprisingly, the dropout layer didn't significantly affect performance, and the best results were obtained without it. The number of epochs was found to have the most significant impact on performance, while the Keras tuner's suggestion of adding dropout didn't result in noticeable improvements in performance..\n",
    "\n",
    "My best model (LSTM + Word Embedding) placed 4th out of 478 models on the public leaderboard.\n",
    "\n",
    "Link to main repository: [SST - Sentiment Analysis](https://github.com/timnyt/ML-Projects/tree/main/SST%20-%20Sentiment%20Analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
